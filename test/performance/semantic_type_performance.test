# name: test/performance/semantic_type_performance.test
# description: Performance tests for semantic type system
# group: [duckdb_ast]

require duckdb_ast

# Test 1: Baseline parsing performance (measure overhead of semantic type population)
statement ok
CREATE TABLE perf_baseline AS
WITH timings AS (
    SELECT 
        epoch_ms(current_timestamp) as start_time,
        (SELECT COUNT(*) FROM parse_ast(repeat('x = 1 + 2; ', 1000), 'python')) as node_count,
        epoch_ms(current_timestamp) as end_time
)
SELECT 
    node_count,
    end_time - start_time as parse_time_ms,
    ROUND(node_count::DOUBLE / (end_time - start_time), 2) as nodes_per_ms
FROM timings;

# Test 2: Semantic type lookup performance
statement ok
CREATE TABLE perf_semantic_lookup AS
WITH large_ast AS (
    SELECT * FROM parse_ast(repeat('def func(): return x + y * z; ', 100), 'python')
),
timings AS (
    SELECT 
        epoch_ms(current_timestamp) as start_time,
        (SELECT COUNT(*) FROM large_ast WHERE semantic_type = 52) as func_count,
        (SELECT COUNT(*) FROM large_ast WHERE semantic_type = 160) as op_count,
        (SELECT COUNT(*) FROM large_ast WHERE semantic_type = 192) as id_count,
        epoch_ms(current_timestamp) as end_time
)
SELECT 
    func_count,
    op_count,
    id_count,
    end_time - start_time as lookup_time_ms
FROM timings;

# Test 3: Cross-language semantic normalization performance
statement ok
CREATE TABLE perf_cross_language AS
WITH 
py_ast AS (SELECT semantic_type, type FROM parse_ast(repeat('def f(x): return x + 1; ', 50), 'python')),
js_ast AS (SELECT semantic_type, type FROM parse_ast(repeat('function f(x) { return x + 1; } ', 50), 'javascript')),
cpp_ast AS (SELECT semantic_type, type FROM parse_ast(repeat('int f(int x) { return x + 1; } ', 50), 'cpp')),
timings AS (
    SELECT 
        epoch_ms(current_timestamp) as start_time,
        (
            SELECT COUNT(*) FROM py_ast p
            JOIN js_ast j ON p.semantic_type = j.semantic_type
            JOIN cpp_ast c ON j.semantic_type = c.semantic_type
            WHERE p.semantic_type IN (52, 160, 192)  -- Functions, operators, identifiers
        ) as matched_nodes,
        epoch_ms(current_timestamp) as end_time
)
SELECT 
    matched_nodes,
    end_time - start_time as join_time_ms
FROM timings;

# Test 4: Bitfield operations performance
statement ok
CREATE TABLE perf_bitfield_ops AS
WITH large_ast AS (
    SELECT semantic_type FROM parse_ast(repeat('async def f(): await x(); yield y; ', 100), 'python')
),
timings AS (
    SELECT 
        epoch_ms(current_timestamp) as start_time,
        -- Extract super_kind (bits 6-7): 1 = SEMANTIC 
        (SELECT COUNT(*) FROM large_ast WHERE (semantic_type >> 6) & 3 = 1) as semantic_nodes,
        -- Extract kind (bits 4-5): 3 = DEFINITION
        (SELECT COUNT(*) FROM large_ast WHERE (semantic_type >> 4) & 3 = 3) as definition_nodes,
        -- Extract super_type (bits 2-3): 1 = FUNCTION subtype
        (SELECT COUNT(*) FROM large_ast WHERE (semantic_type >> 2) & 3 = 1) as function_subtype_nodes,
        epoch_ms(current_timestamp) as end_time
)
SELECT 
    semantic_nodes,
    definition_nodes,
    function_subtype_nodes,
    end_time - start_time as bitop_time_ms
FROM timings;

# Test 5: Memory efficiency - struct size comparison
query III
WITH ast_data AS (
    SELECT ast FROM read_ast_objects('test/data/python/simple.py')
),
size_info AS (
    SELECT 
        LENGTH(ast::VARCHAR) as total_bytes,
        array_length(ast.nodes) as node_count,
        ROUND(LENGTH(ast::VARCHAR)::DOUBLE / array_length(ast.nodes), 2) as bytes_per_node
    FROM ast_data
)
SELECT 
    total_bytes,
    node_count,
    bytes_per_node
FROM size_info;
----
# Results will vary but should show efficient storage

# Test 6: Semantic type distribution analysis
query IIII
WITH semantic_stats AS (
    SELECT 
        semantic_type,
        COUNT(*) as count,
        ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER(), 2) as percentage
    FROM parse_ast('
        class Calculator:
            def __init__(self):
                self.value = 0
            
            def add(self, x):
                self.value += x
                return self.value
            
            def multiply(self, x):
                self.value *= x
                return self.value
    ', 'python')
    GROUP BY semantic_type
    ORDER BY count DESC
    LIMIT 5
)
SELECT 
    semantic_type,
    count,
    percentage,
    CASE semantic_type
        WHEN 0 THEN 'PARSER_CONSTRUCT'
        WHEN 192 THEN 'IDENTIFIER_COMMON'
        WHEN 172 THEN 'OPERATOR_ASSIGNMENT'
        WHEN 52 THEN 'DEFINITION_FUNCTION'
        WHEN 100 THEN 'COMPUTATION_ACCESS'
        ELSE 'OTHER'
    END as semantic_name
FROM semantic_stats;
----
# Top semantic types should be parser constructs, identifiers, and operators

# Test 7: Lazy initialization performance
statement ok
CREATE TABLE perf_lazy_init AS
WITH timings AS (
    -- First use of Rust (should trigger initialization)
    SELECT 
        epoch_ms(current_timestamp) as rust_start,
        (SELECT COUNT(*) FROM parse_ast('fn main() { println!("test"); }', 'rust') LIMIT 1) as _,
        epoch_ms(current_timestamp) as rust_end,
        -- Second use of Rust (should be fast)
        epoch_ms(current_timestamp) as rust2_start,
        (SELECT COUNT(*) FROM parse_ast('fn test() -> i32 { 42 }', 'rust') LIMIT 1) as _,
        epoch_ms(current_timestamp) as rust2_end
)
SELECT 
    rust_end - rust_start as first_rust_ms,
    rust2_end - rust2_start as second_rust_ms,
    CASE 
        WHEN (rust_end - rust_start) > (rust2_end - rust2_start) 
        THEN 'LAZY_INIT_WORKING'
        ELSE 'LAZY_INIT_NOT_DETECTED'
    END as status
FROM timings;

# Summary query to verify all performance tests completed
query I
SELECT COUNT(*) = 7 as all_tests_completed
FROM (
    SELECT 'baseline' as test FROM perf_baseline
    UNION ALL
    SELECT 'semantic_lookup' FROM perf_semantic_lookup
    UNION ALL
    SELECT 'cross_language' FROM perf_cross_language
    UNION ALL
    SELECT 'bitfield_ops' FROM perf_bitfield_ops
    UNION ALL
    SELECT 'lazy_init' FROM perf_lazy_init
);
----
true